const _ = require("lodash");
const kafka_node = require("kafka-node");
const Rx = require("rxjs");
const {filter, take, publish, map, takeWhile, catchError, tap} = require("rxjs/operators");
const async = require("async");
const Kafka = require("node-rdkafka");
const EventEmitter = require("events");

/**
 * Enum for consuming limits
 * @enum {number}
 */
let LIMIT_OFFSET = {
	"end": -1,
	"latest": -1,
};

class WrongLimitOffsetException extends Error {
	constructor (toppar) {
		super(`Задано неверное значение для оффсета - ${ JSON.stringify(toppar) }`);
		this.name = "WrongLimitOffset";
	}
}

class LimitOffsetNotSetException extends Error {
	constructor (toppar) {
		super(`Не задано значение для оффсета - ${ JSON.stringify(toppar) }`);
		this.name = "LimitOffsetNotSet";
	}
}

class ConsumingFinishedException extends Error {
	constructor () {
		super("");
		this.name = "ConsumingFinished";
	}
}

function getConsumerClass () {
	return class Consumer extends EventEmitter {
		/**
		 * 
		 * @param {Object} params
		 * @param {Object} params.config - Global consumer config (https://github.com/edenhill/librdkafka/blob/0.11.1.x/CONFIGURATION.md#global-configuration-properties)
		 * @param {Object={}} params.topic_config - topic configuration (https://github.com/edenhill/librdkafka/blob/0.11.1.x/CONFIGURATION.md#topic-configuration-properties)
		 * @param {string[]=} params.topics - topics to subscribe
		 * @param {{topic: string, partition: number, ?offset: number}[]=} params.assignments - toppars to assign. If offset is set, then consuming starts from that offset, otherwise, from last commited offset for that partition
		 * @param {{topic: string, partition: number, offset: (number|LIMIT_OFFSET)}[]=} params.limits - offset is the last offset to consume.
		 * @param {boolean=true} params.supressBrokerError - whether ignore "broker transport failure" error or not
		 */
		constructor ({config, topic_config = {}, topics, assignments, limits, supressBrokerError = true}) {
			super();
			this.config = _.cloneDeep(config);
			this.supress_broker_error = supressBrokerError;
			this.topic_config = _.cloneDeep(topic_config);
			this.topics = topics;
			this.assignments = assignments;
			this.limits = limits;
			this.consumer;
			this.consumer_observable;
			this.rebalance_observable;
			this.event_observable;
			this.error_observable;
			this.connected = false;
			this.ready = false;
			this.closed = false;
			this.disconnected = true;
			this.error_bus = new Rx.Subject();
		}
		
		/**
		 * Main method after consumer creation to invoke.
		 * @emits Consumer#connected
		 * @param {Object={}} params
		 * @param {Object} params.metadata_options - Metadata options for node-rdkafka connection
		 * @throws node-rdkafka connection error
		 */
		async connect ({metadata_options} = {}) {
			let {consumer, consumer_observable} = await this.createReactiveConsumer({config: this.config, topic_config: this.topic_config, topics: this.topics, assignments: this.assignments, limits: this.limits, metadata_options});
			this.consumer = consumer;
			this.consumer_observable = consumer_observable;
			this.initEvents(consumer);
			this.connected = true;
			this.ready = true;
			this.disconnected = false;
			/**
			 * Connected event after successful connection
			 * @event Consumer#disconnected
			 */
			this.emit("connected");
		}

		/**
		 * @name consume_next
		 * @function
		 * @param {Object=} error - error instance
		 * @returns undefined
		 */

		/**
		 * @name consume_finish
		 * @function
		 * @returns undefined
		 */

		/**
		 * @callback Consumer~consumeCallback
		 * @param {{topic: string, partition: number, offset: message, key: string, value: buffer, timestamp: number}} message - message object
		 * @param {consume_next} next - callback to process next message
		 * @param {consume_finish} next.finish - function to finish consuming
		*/
		
		/**
		 * Method to consume messages from kafka one by one.
		 * @param {Consumer~consumeCallback} callback - function in which procesing is taking place
		 * @returns {Promise} Promise object resolves when internal while loop breaks after error. Error will be emitted by the "error" event or by error observable
		 */
		consume (callback) {
			let self = this;
			let run = true;
			return new Promise (resolve => {
				async.whilst(
					() => true,
					(cb) => {
						let message_promise = self.consumer_observable.pipe(take(1), map(({action_data}) => action_data)).toPromise();
						
						message_promise
						.then(async (message) => {
							let consume_callback = (err) => {
								cb(err);
							};
							consume_callback.finish = () => {
								cb(new ConsumingFinishedException());
							};
							try {
								await callback(message, consume_callback); // этот await нам нужен для отлова необработанных ошибок в самой функции callback
							} catch (err) {
								cb(err);
							}
						})
						.catch(err => {
							cb(err);
						});
					},
					err => {
						if (!(err instanceof ConsumingFinishedException)) {
							this.error_bus.next(err);
						}
						resolve();
					}
				);
			});
		}
		
		/**
		 * Method to disconnect from kafka and dispose resources
		 * @emits Consumer#disconnected
		 */
		disconnect () {
			this.consumer.disconnect();
			this.ready = false;
			this.closed = true;
			this.disconnected = true;
			this.connected = false;
			/**
			 * Disconnected event
			 * @event Consumer#disconnected
			 */
			this.emit("disconnected");
		}

		/**
		 * Consequently invokes event initializers
		 * @private
		 * @param {Object} consumer node-rdkafka Consumer object 
		 */
		initEvents (consumer) {
			this.initRebalanceProcessor(consumer);
			this.initErrorProcessor(consumer);
			this.initRdKafkaEventsProcessor(consumer);
		}

		/**
		 * Creates rebalance observable and re-emits "rebalance" event from node-rdkafka
		 * @private
		 * @param {Object} consumer node-rdkafka Consumer object  
		 */
		initRebalanceProcessor (consumer) {
			consumer.on("rebalance", (err, assignments) => {
				this.emit("rebalance", err, assignments);
			});
			this.rebalance_observable = Rx.fromEvent(this, "rebalance", {}, (err, assignments) => {
				if ((err.code === Kafka.CODES.ERRORS.ERR__ASSIGN_PARTITIONS)) {
					return {action: "rebalance", action_data: {type: "assign", assignments, error: err}};
				} else if (err.code === Kafka.CODES.ERRORS.ERR__REVOKE_PARTITIONS) {
					return {action: "rebalance", action_data: {type: "revoke", assignments, error: err}};
				} else {
					//throw err;
					return {action: "rebalance", action_data: {type: "error", assignments, error: err}};
				}
			}).pipe(publish()).refCount();
		}

		/**
		 * Creates error observable and re-emits "event.error", rebalance error, and errors from Internal Error Bus.
		 * @private
		 * @param {Object} consumer node-rdkafka Consumer object  
		 */
		initErrorProcessor (consumer) {
			let self = this;
			let event_error_obs = Rx.fromEvent(consumer, "event.error").pipe(
				filter(err => {
					if (self.supress_broker_error && err.message === "broker transport failure") {
						return false;
					}
					return true;
				})
			);

			let rebalance_error_obs = this.rebalance_observable.pipe(
				/*catchError(err => Rx.of({action_data: {type: "error", error: err}})),*/
				filter(({action_data}) => {
					return action_data.type === "error"
				}),
				map(({action_data}) => {
					return action_data.error;
				})
			)
			/* здесь мы, сначала, создаем объединенный Observable для всех ошибок, и подписавшись к нему, делаем emit события error.
			   а, уж затем, создаем error_observable, который уже будет слушать это событие.
			   Вы можете спросить, а зачем так делать? - Можно, ведь, сначала создать необходимый error_observable, а затем создать event emitter из него?
			   Но, тогда, возникает проблема: при использовании инстанса данного Consumer, только с error_observable, не подписываясь на события error (.on("error")), 
			   то NodeJS будет выкидывать исключение Error: Unhandled "error" event. ([object Object]). Чтобы этого не было, мы используем данный трюк.
			   Таким образом, если мы подпишемся только к error_observable, то у нас будет минимум 1 подписчик на события error. 
			*/
			Rx.merge(
				this.error_bus,
				rebalance_error_obs,
				event_error_obs
			).subscribe(err => {
				self.emit("error", err);
			});
			
			this.error_observable = Rx.fromEvent(this, "error", {}, err => {
				return {action: "error", action_data: err};
			}).pipe(publish()).refCount();
		}
		/**
		 * Creates event observable and re-emits "event", "event.log", "event.stats", "event.throttle" events from node-rdkafka
		 * @private
		 * @param {Object} consumer node-rdkafka Consumer object  
		 */
		initRdKafkaEventsProcessor (consumer) {
			let events = ["event", "event.log", "event.stats", "event.throttle"];
			let events_observables = [];
			for (let event of events) {
				consumer.on(event, (...args) => {
					this.emit(event, ...args);
				});
				events_observables.push(Rx.fromEvent(this, event).pipe(
					map(event_data => { return {action: event, action_data: event_data}; })
				));
			}
			this.event_observable = Rx.merge(...events_observables).pipe(
				publish()
			).refCount();
		}
		
		/**
		 * Method to request watermark offsets from Kafka Broker
		 * @param {Object} params
		 * @param {Object=} params.consumer node-rdkafka consumer instance. May be omitted
		 * @param {string} params.topic
		 * @param {number} params.partition
		 * @param {number=30000} params.timeout timeout in ms to wait for response from broker
		 * @returns {{highOffset: number, lowOffset: number}} watermark for topic, partition pair. lowOffset - minimum available offset in partition. highOffset - latest message's offset in partition
		 */
		queryWatermarkOffsets ({consumer, topic, partition, timeout = 30000}) {
			if (!consumer) { // инстанс консьюмера будет передан только во время инициализации, т.к. к этому моменту еще не будет доступен this.consumer. А после инициализцаии, будем использовать this.consumer
				consumer = this.consumer;
			}
			return new Promise ((resolve, reject) => {
				consumer.queryWatermarkOffsets(topic, partition, timeout, (err, watermark) => {
					if (err) {
						reject(err);
					} else {
						resolve(watermark);
					}
				});
			});
		}

		/**
		 * Requests topic metadata from broker
		 * @param {string} topic
		 * @returns {Object} topic metadata (https://blizzard.github.io/node-rdkafka/current/Client.html#~Metadata)
		 */
		getMetadata (topic) {
			return new Promise ((resolve, reject) => {
				this.consumer.getMetadata({topic}, (err, metadata) => {
					if (err) {
						reject(err);
					} else {
						resolve(metadata);
					}
				});
			});
		}
	
		async createReactiveConsumer ({config, topic_config, metadata_options, topics, assignments, limits}) {
			if (limits) {
				/*
					Логика такая - при создании реактивного консьюмера создается новый инстанс консьюмера и подключается к топикам и партициям по заданным оффсетам (assignments и positions)
					Затем, мы создаем multicasted observable (MO) с refCount (подсчетом подписок) из реактивного консьюмера (РК), чтобы при подписке на РК не создавались новые инстансы консьюмера , а использовалачь одна и та же подписка.
					Затем, к MO подключаются toppar_observable, каждый из которых отвечает за сообщения из определнного топика и партиции + следит за лимитом. Затем все toppar_observable объединяются методом Rx.merge (получаем комплексный observable (CO))
					Когда, мы подключаемся к CO, происходит:
					* подключение CO к каждому toppar_observable
					* подключение каждого toppar_observable к MO, при котором счетчик подписок (refCount) в MO увеличивается на общее количество toppar_observable
					* подключение MO к самому РК, вследствие увеличения refCount (refCount != 0)
					* начало считывания сообщений из Кафки (получение сообщений из внутреннего кэша node-rdkafka)
					Когда каждый toppar_observable достигнет лимита количества сообщений (оператор take) или мы вручную вызовем отпишемся (unsubscribe) от CO (когда уже обработаем все, вероятно отправленные, сообщения),
					то произойдут следующие действия:
					* CO отпишется от каждого toppar_observable
					* Каждый toppar_observable отпищется от MO, доведя refCount до нуля
					* Вследствие отсутствия активных подписок в MO (refCount === 0), MO отпишется от РК
					* Из-за того, что РК - это cold observable (при каждой подписке (subscription) происходит создание консьюмера), то, когда произойдет отписка,
						консьюмер отсоединится (disconnect) от Кафки.
				*/
				let {consumer, consumer_observable} = await this.__createReactiveConsumer ({config, topic_config, metadata_options, topics, assignments});
				let consumer_observable_multicasted = consumer_observable.pipe(publish()).refCount();
				let channel_observables = await Promise.all(limits.map(async ({topic, partition, offset: _offset}) => {
					let offset;
					if (typeof(_offset) === "string") {
						if (!(_offset in LIMIT_OFFSET)) {
							throw new LimitOffsetNotSetException({topic, partition, offset: _offset});
						} else {
							offset = LIMIT_OFFSET[_offset];
						}
					} else if (typeof(_offset) === "number") {
						offset = _offset;
					} else {
						throw new WrongLimitOffsetException({topic, partition, offset: _offset});
					}

					if (offset === -1) {
						offset = (await this.queryWatermarkOffsets({consumer, topic, partition}))["highOffset"];
					}
					return consumer_observable_multicasted.pipe(
						filter(({action, action_data}) => action === "data" && action_data.topic === topic && action_data.partition === partition),
						takeWhile(({action_data}) => {
							return action_data.offset <= offset;
						})
					);
				}));
				return {consumer, consumer_observable: Rx.merge(...channel_observables)};
			} else {
				let {consumer, consumer_observable} = await this.__createReactiveConsumer ({config, topic_config, metadata_options, topics, assignments, hot: true});
				return {consumer, consumer_observable};
			}
		}
	
		async __createReactiveConsumer ({config, topic_config, metadata_options, topics, assignments, hot = false}) {
			let self = this;
			let consumer = await this.createConsumer({config, topic_config, metadata_options, topics, assignments});
	
			let observable = Rx.defer(() => Rx.Observable.create(observer => {
				let subscription_alive = true;
				// считываем сообщения по-одному, пока не прекратится подписка или не возникнет ошибка
				async.whilst(
					() => subscription_alive,
					callback => {
						consumer.consume(1, (err, msgs) => {
							// Здесь мы используем setImmediate т.к. в случае получения результата вызова consumer.consume синхронно (т.е. если переданный callback будет вызван синхронно, т.е. в коде consumer.consume не будет асинхронных действий),
							// то мы получим RangeError: Maximum call stack size exceeded, т.к. async.whilst будет делать вложенные вызовы функции, которая отвечает за отправку данных в observer 
							if (err) {
								setImmediate(() => {
									observer.error(err);
									callback(err);
								});
									
							} else if (msgs.length > 0) {
								setImmediate(() => {
									observer.next({action: "data", action_data: msgs[0]});
									callback();
								});
							} else { // msgs - пустой
								setImmediate(callback);
							}
						});
					}
				);
				return () => {
					subscription_alive = false;
					if (!hot && consumer) { // может получиться так, что consumer может и не создасться к этому моменту
						self.disconnect();
					}
				};			
			}));
			
			return {consumer, consumer_observable: observable};
		}
		
		createConsumer ({config, topic_config = {}, topics, assignments, metadata_options = {}}) {
			return new Promise ((resolve, reject) => {
				let consumer = new Kafka.KafkaConsumer(config, topic_config);
				consumer.connect(metadata_options, err => {
					if (err) {
						reject(err);
					} else {
						if (assignments) {
							consumer.assign(assignments);
						} else {
							consumer.subscribe(topics);
						}
						resolve(consumer);
					}
				});
			});
		}

		getObservable () {
			return this.consumer_observable;
		}

		commitSync ({topic, partition, offset}) {
			return this.consumer.commitSync({topic, partition, offset});
		}
	
		commitMessageSync (message) {
			return this.consumer.commitMessageSync(message);
		}

		getRebalanceObservable () {
			return this.rebalance_observable;
		}

		getErrorObservable () {
			return this.error_observable;
		}

		getEventObservable () {
			return this.event_observable;
		}
	};
}

function getProducerClass () {
	return class Producer extends EventEmitter {
		constructor ({config, pollInterval = 100, supressBrokerError = true}) {
			super();
			this.config = _.omit(Object.assign(_.cloneDeep(config), {"dr_msg_cb": true}), "dr_cb");
			this.supress_broker_error = supressBrokerError;
			this.pollInterval = pollInterval;
			this.connected = false;
			this.disconnected = true;
			this.closed = false;
			this.ready = false;
			this.producer;
			this.error_observable;
			this.event_observable;
			this.error_bus = new Rx.Subject();
		}
		
		async connect ({metadata_options = {}} = {}) {
			let producer = await this.createProducer({config: this.config, metadata_options});
			this.initEvents(producer);
			this.producer = producer;
			this.connected = true;
			this.ready = true;
			this.disconnected = false;
			this.emit("connected");
		}

		initEvents (producer) {
			this.initErrorProcessor(producer);
			this.initRdKafkaEventsProcessor(producer);
		}

		initErrorProcessor (producer) {
			let self = this;
			let event_error_obs = Rx.fromEvent(producer, "event.error").pipe(
				filter(err => {
					if (self.supress_broker_error && err.message === "broker transport failure") {
						return false;
					}
					return true;
				})
			);

			Rx.merge(
				this.error_bus,
				event_error_obs
			).subscribe(err => {
				self.emit("error", err);
			});
			
			this.error_observable = Rx.fromEvent(this, "error", {}, err => {
				return {action: "error", action_data: err};
			}).pipe(publish()).refCount();
		}

		initRdKafkaEventsProcessor (producer) {
			let events = ["event", "event.log", "event.stats", "event.throttle"];
			let events_observables = [];
			for (let event of events) {
				producer.on(event, (...args) => {
					this.emit(event, ...args);
				});
				events_observables.push(Rx.fromEvent(this, event).pipe(
					map(event_data => { return {action: event, action_data: event_data}; })
				));
			}
			this.event_observable = Rx.merge(...events_observables).pipe(
				publish()
			).refCount();
		}
	
		async disconnect () {
			this.producer.disconnect();
			this.connected = false;
			this.disconnected = true;
			this.closed = true;
			this.ready = false;
			this.emit("disconnected");
		}
	
		createProducer ({config, metadata_options = {}} = {}) {
			let self = this;
			return new Promise((resolve, reject) => {
				config = Object.assign(config, {"dr_msg_cb": true});
				let producer = new Kafka.Producer(config);
				producer.connect(metadata_options, (err) => {
					if (err) {
						reject(err);
					} else {
						producer.setPollInterval(self.pollInterval);
						producer.on("ready", () => {
							resolve(producer);
						});
						producer.on("delivery-report", (err, report) => {
							report.opaque.cb(err, report);
						});
						resolve(producer);
					}
				});
			});
		}
	
		produce (topic, partition, value, key, timestamp) {
			let self = this;
			return new Promise ((resolve, reject) => {
				self.producer.produce(topic, partition, value, key, timestamp, {
					cb: async (err, msg) => {
						if (err) {
							reject(err);
						} else {
							resolve(msg);
						}
					}
				});
			});
		}

		getObservable () {
			return this.consumer_observable;
		}

		getErrorObservable () {
			return this.error_observable;
		}

		getEventObservable () {
			return this.event_observable;
		}
	};
}

function getAdminClass () {
	return class Admin {
		constructor ({config}) {
			this.config = config;
			this.admin;
			this.init();
		}
	
		init () {
			let client = new kafka_node.KafkaClient(this.config);
			this.admin = new kafka_node.Admin(client);
		}
	
		getConsumerStatus ({group_id, consumer_id}) {
			return new Promise ((resolve, reject) => {
				self.admin.describeGroups([group_id], (err, res) => {
					if (err) {
						reject(err);
					} else {
						res = res[group_id].members.find(_member => _member.clientId === consumer_id);
						if (!res) {
							resolve({alive: false});
						} else {
							resolve({alive: true, consumer_data: res});
						}
					}
				});
			});
		}
	};
}

module.exports.Consumer = getConsumerClass();
module.exports.Producer = getProducerClass();
module.exports.Admin = getAdminClass();
module.exports.getConsumerClass = getConsumerClass;
module.exports.getProducerClass = getProducerClass;
module.exports.getAdminClass = getAdminClass;